{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8671460-bb39-4537-8032-eadef3940388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivos originais carregados com sucesso!\n",
      "Expandindo df_minamin para segundos...\n",
      "df_minamin expandido para 9660 linhas (segundos).\n",
      "\n",
      "Expandindo df_espelho para segundos...\n",
      "df_espelho expandido para 8367 linhas (segundos).\n",
      "\n",
      "Realizando merge em nível de segundo...\n",
      "Merge finalizado. Total de 9660 linhas.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Temp\\ipykernel_16092\\2242554504.py:59: FutureWarning: 'S' is deprecated and will be removed in a future version, please use 's' instead.\n",
      "  segundos_no_intervalo = pd.date_range(row['datetime_inicio_espelho_seg'], row['datetime_fim_espelho_seg'], freq='S')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Arquivo mergeado em segundos salvo em: audiencia_espelho_merged_segundos.csv\n",
      "\n",
      "Informações do df_merged_segundos:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9660 entries, 0 to 9659\n",
      "Columns: 13 entries, HORA to Ordem\n",
      "dtypes: datetime64[ns](1), float64(6), object(6)\n",
      "memory usage: 981.2+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Carregar os dataframes originais\n",
    "# Certifique-se de que os arquivos CSV estão no mesmo diretório do script\n",
    "# ou forneça o caminho completo para eles.\n",
    "try:\n",
    "    df_minamin_orig = pd.read_excel(\"Realtime_clean.xlsx\")\n",
    "    df_espelho_orig = pd.read_excel(\"Espelho BDES.xlsx\")\n",
    "    print(\"Arquivos originais carregados com sucesso!\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"ERRO CRÍTICO: Arquivo não encontrado - {e.filename}\")\n",
    "    print(\"Por favor, verifique o nome e o local dos arquivos CSV de entrada.\")\n",
    "    df_minamin_orig = None # Garante que não prossiga se houver erro\n",
    "    df_espelho_orig = None\n",
    "\n",
    "# Prosseguir somente se ambos os dataframes foram carregados\n",
    "if df_minamin_orig is not None and df_espelho_orig is not None:\n",
    "\n",
    "    # --- 1. Expandir df_minamin para segundos ---\n",
    "    print(\"Expandindo df_minamin para segundos...\")\n",
    "    df_minamin = df_minamin_orig.copy() # Trabalhar com uma cópia\n",
    "    df_minamin['HORA_base'] = pd.to_datetime(df_minamin['HORA'], format='%H:%M:%S', errors='coerce')\n",
    "    df_minamin.dropna(subset=['HORA_base'], inplace=True)\n",
    "\n",
    "    minamin_segundos_list = []\n",
    "    for _, row in df_minamin.iterrows():\n",
    "        minuto_base = row['HORA_base']\n",
    "        # Criar 60 segundos para este minuto\n",
    "        for segundo_offset in range(60):\n",
    "            new_row_data = row.to_dict()\n",
    "            # Adiciona a data base '1900-01-01' para consistência no datetime\n",
    "            new_row_data['datetime_segundo_audiencia'] = pd.to_datetime('1900-01-01 ' + (minuto_base + pd.Timedelta(seconds=segundo_offset)).strftime('%H:%M:%S'))\n",
    "            minamin_segundos_list.append(new_row_data)\n",
    "\n",
    "    df_minamin_segundos = pd.DataFrame(minamin_segundos_list)\n",
    "    df_minamin_segundos.drop(columns=['HORA_base'], inplace=True, errors='ignore')\n",
    "    df_minamin_segundos.sort_values('datetime_segundo_audiencia', inplace=True)\n",
    "    print(f\"df_minamin expandido para {len(df_minamin_segundos)} linhas (segundos).\")\n",
    "\n",
    "    # --- 2. Expandir df_espelho para segundos ---\n",
    "    print(\"\\nExpandindo df_espelho para segundos...\")\n",
    "    df_espelho = df_espelho_orig.copy() # Trabalhar com uma cópia\n",
    "    df_espelho.rename(columns={'Início (Lauda)': 'inicio_lauda', 'Fim (Lauda)': 'fim_lauda'}, inplace=True)\n",
    "\n",
    "    # Converte para time e depois adiciona a data base '1900-01-01'\n",
    "    df_espelho['inicio_lauda_dt_time'] = pd.to_datetime(df_espelho['inicio_lauda'], format='%H:%M:%S', errors='coerce').dt.time\n",
    "    df_espelho['fim_lauda_dt_time'] = pd.to_datetime(df_espelho['fim_lauda'], format='%H:%M:%S', errors='coerce').dt.time\n",
    "\n",
    "    df_espelho.dropna(subset=['inicio_lauda_dt_time', 'fim_lauda_dt_time'], inplace=True)\n",
    "\n",
    "    df_espelho['datetime_inicio_espelho_seg'] = pd.to_datetime('1900-01-01 ' + df_espelho['inicio_lauda_dt_time'].astype(str))\n",
    "    df_espelho['datetime_fim_espelho_seg'] = pd.to_datetime('1900-01-01 ' + df_espelho['fim_lauda_dt_time'].astype(str))\n",
    "\n",
    "    # Garantir que fim >= inicio\n",
    "    df_espelho = df_espelho[df_espelho['datetime_fim_espelho_seg'] >= df_espelho['datetime_inicio_espelho_seg']]\n",
    "\n",
    "    espelho_segundos_list = []\n",
    "    for _, row in df_espelho.iterrows():\n",
    "        segundos_no_intervalo = pd.date_range(row['datetime_inicio_espelho_seg'], row['datetime_fim_espelho_seg'], freq='S')\n",
    "        \n",
    "        for segundo_ts in segundos_no_intervalo:\n",
    "            new_row_data = row.to_dict()\n",
    "            new_row_data['datetime_segundo_espelho'] = segundo_ts\n",
    "            espelho_segundos_list.append(new_row_data)\n",
    "\n",
    "    if espelho_segundos_list:\n",
    "        df_espelho_segundos = pd.DataFrame(espelho_segundos_list)\n",
    "        df_espelho_segundos.drop(columns=['inicio_lauda_dt_time', 'fim_lauda_dt_time', \n",
    "                                          'datetime_inicio_espelho_seg', 'datetime_fim_espelho_seg'], \n",
    "                                 inplace=True, errors='ignore')\n",
    "        df_espelho_segundos.sort_values('datetime_segundo_espelho', inplace=True)\n",
    "        df_espelho_segundos.drop_duplicates(subset=['datetime_segundo_espelho'], keep='first', inplace=True)\n",
    "        print(f\"df_espelho expandido para {len(df_espelho_segundos)} linhas (segundos).\")\n",
    "    else:\n",
    "        print(\"Não foi possível expandir df_espelho. Verifique os dados de início/fim.\")\n",
    "        df_espelho_segundos = pd.DataFrame(columns=['datetime_segundo_espelho', 'Bloco', 'Tipo', 'Retranca', 'Ordem', 'inicio_lauda', 'fim_lauda'])\n",
    "\n",
    "\n",
    "    # --- 3. Merge em Nível de Segundo ---\n",
    "    print(\"\\nRealizando merge em nível de segundo...\")\n",
    "    df_merged_segundos = pd.merge(\n",
    "        df_minamin_segundos,\n",
    "        df_espelho_segundos,\n",
    "        left_on='datetime_segundo_audiencia',\n",
    "        right_on='datetime_segundo_espelho',\n",
    "        how='left'\n",
    "    )\n",
    "    df_merged_segundos.drop(columns=['datetime_segundo_espelho'], inplace=True, errors='ignore')\n",
    "    print(f\"Merge finalizado. Total de {len(df_merged_segundos)} linhas.\")\n",
    "\n",
    "    # --- 4. Salvar ---\n",
    "    output_path_segundos = \"audiencia_espelho_merged_segundos.csv\"\n",
    "    df_merged_segundos.to_csv(output_path_segundos, index=False, encoding='utf-8-sig')\n",
    "    print(f\"\\nArquivo mergeado em segundos salvo em: {output_path_segundos}\")\n",
    "\n",
    "    print(\"\\nInformações do df_merged_segundos:\")\n",
    "    df_merged_segundos.info(verbose=False) # verbose=False para um resumo mais curto\n",
    "else:\n",
    "    print(\"\\nUm ou ambos os DataFrames de entrada não foram carregados. O script não pode continuar.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a489f8-f24e-49b9-9763-9786a31301a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Espelho)",
   "language": "python",
   "name": "espelho"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
